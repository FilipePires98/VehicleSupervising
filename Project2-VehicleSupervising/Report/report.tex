\documentclass[12pt]{article}

\usepackage{scicite,times,graphicx,float,hyperref}
\usepackage[skip=0pt]{caption}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{booktabs}

\topmargin -1.0cm
\oddsidemargin 0.0cm
\textwidth 16cm 
\textheight 23cm
\footskip 1.0cm

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}

\newcounter{lastnote}
\newenvironment{scilastnote}{%
  \setcounter{lastnote}{\value{enumiv}}%
  \addtocounter{lastnote}{+1}%
  \begin{list}%
  {\arabic{lastnote}.}
  {\setlength{\leftmargin}{.22in}}
  {\setlength{\labelsep}{.5em}}
}
{\end{list}}

\title{A Kafka-Based Centralized Platform\\for Smart Vehicle Supervising} 

\author
{Filipe Pires [85122], João Alegria [85048]\\
\\
Software Architecture\\
\normalsize{Department of Electronics, Telecommunications and Informatics}\\
\normalsize{University of Aveiro}\\
} 

\date{\today{}}

%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%

\begin{document} 

\baselineskip18pt

\maketitle 

\section*{Introduction} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This report aims to describe the work developed for the second assignment of the course of 'Software Architecture', focused on a platform that collects and 
processes information from simulated vehicles.

The aim of the assignment was to explore the capabilities of a technology like Kafka in standard IoT solutions.
The system itself isn't meant to provide a field-tested solution to a problem or a set of problems, rather it is supposed to show how communications via Kafka 
can empower developers in a time that modularity is more important than ever and system components must be prepared to easily transfer data streams between each other.

So in this report we present the architecture of our solution and the Kafka-related configurations, justifying them according to what we learned and found to be 
most suitable for each specific use case.
We also mention how the work was distributed amongst the authors.

All code developed is publicly accessible in our GitHub repository:

\url{https://github.com/FilipePires98/AS/}

% \vspace{-10pt}
% \begin{itemize}[noitemsep]
%   \item Prepare - the selected farmers move to a Standing Area, ready for orders.
%   \item Start - the actual simulation begins and farmers start moving.
%   \item Collect - farmers collect corn cobs from the Granary (where the cobs initially are).
%   \item Return - farmers return to the Storehouse with the collected corn cobs.
%   \item Stop - farmers stop whatever they are doing and return to the Storehouse.
%   \item Exit - simulation ends and the program closes.
% \end{itemize}
% \vspace{-10pt}

% \begin{figure}[H]
%   \centering
%   \begin{minipage}{\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{img/Design_FI.png}
%   \end{minipage}%
%   \caption{Visual representation of the farm, taken from \cite{assign}.}
%   \label{Design_FI}
% \end{figure} 

%\texttt{java -cp <userdir>/build/classes fi.FarmInfrastructure}

\newpage
\section{IoT, Kafka and Connected Devices} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Internet of Things (IoT) is becoming an increasing topic of interest among technology giants and business communities.
IoT Components are interconnected devices over a network, which are embedded with sensors, software and smart applications so they can collect and exchange data 
with each other or with cloud / data centers.

One of the areas in which IoT is paving its way is the connected vehicles. 
According to Gartner predictions \cite{gartner}, by this year there should be about a quarter-billion connected vehicles on the road, which are more automated, 
providing new in-vehicle services such as enhanced navigation system, real-time traffic updates, weather alerts and integration with monitoring dashboards. 
In order to process the data generated by IoT connected vehicles, data is streamed to central processors usually located in the cloud. 
The collected information can be analysed and data can be extracted and transformed to the final result, which can be sent back to the vehicle or to a monitoring dashboard. 

In this project we explore a hypothetical use case where communication between devices (or entities) is done through Kafka.
Apache Kafka \cite{kafka} is high-throughput distributed messaging system in which multiple producers send data to Kafka cluster and which in turn serves them to consumers. 
It is a distributed, partitioned, replicated commit log service.
The Java application we developed and that is described in this report is a simplified version of an IoT data processing and monitoring application for connected
vehicles, aimed to to explore Kafka capabilities for messaging between entities.

\subsection{The Data} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As having actual connected vehicles with processing units capable of collecting car data and transmitting it to other entities was out of the scope of the project, 
this is simulated through a simple text file containing one transmission (or message) per line.
This data file with the name of \texttt{CAR.TXT} is placed under a specific directory and is read by our system for processing.

In order to dynamically generate such source data, we developed a small script in Python that receives as parameters the number of cars to be simulated and the 
total number of messages to be generated from those cars and stored in the text file.
The script is called \texttt{generateCAR.py} and is placed in the scripts package inside our project.
By default, it creates 10 different cars and writes 100 messages, but these numbers can be easily modified inside the script. 

We used a random-based approach to generate each aspect of a message.
Unique register codes are created to represent vehicles, as well as their status and speeds.
Message types are not generated with a specific pattern, but we made it far more likely to generate a message of type HEARTBEAT (see section \ref{messages}) 
than of any other type.

%A car is characterized by a register code NN-XX-NN, where N is a number between 0 and 9 and X is a letter from the alphabet in uppercase, so we merely compute 
%random numbers within that range and random indexes from 0 to the size of the used alphabet and build register codes. 
%These codes are validated (ensured to be unique) before adding them to an array of car codes.
%Message types are also determined randomly, although some types are made more likely than others, as well as message timestamps, car speeds and car status values.
%The maximum period between messages is of 5 seconds, although this number is also easily configurable inside the script.
%The maximum car speed is of 150 Km per hour and it is assumed that they are only allowed to drive at up to 120 Km per hour.

\subsection{The Messages} \label{messages} %%%%%%%%%%%%%%%%%

Messages can be of 1 of 3 types, each with a specific purpose and format:

\vspace{-10pt}
\begin{itemize}[noitemsep]
  \item HEARTBEAT - the simplest type of message meant to notify the system that the car is still connected. \\ Format: $|$ car\_reg $|$ timestamp $|$ 00 $|$
  \item SPEED - message meant to inform the system about the current speed of the car. This allows the system to determine whether the car is going under the speed limit or not and trigger an alarm if necessary. \\ Format: $|$ car\_reg $|$ timestamp $|$ 01 $|$ speed $|$
  \item STATUS - messages meant to detect whether the smart sensor detects any malfunction. This in theory could help the system provide or suggest a solution for the malfunction to the car driver considering the entire network of connected vehicles. \\ Format: $|$ car\_reg $|$ timestamp $|$ 02 $|$ status $|$
\end{itemize}
\vspace{-10pt}
The car\_reg corresponds to the register code of each vehicle and the timestamp corresponds to the time instance when the message was created, the remaining 
elements are self explanatory.
As we will see, each message type is treated differently both in their purpose and in the care with which their transmission is done. \\
  
$|$ 45-SH-72 $|$ 1586183268975 $|$ 02 $|$ OK $|$

$|$ 28-MC-82 $|$ 1586183269976 $|$ 02 $|$ OK $|$

$|$ 42-UW-71 $|$ 1586183272978 $|$ 00 $|$

$|$ 73-FD-20 $|$ 1586183273979 $|$ 00 $|$

$|$ 28-MC-82 $|$ 1586183274980 $|$ 01 $|$ 20 $|$

$|$ 55-LZ-42 $|$ 1586183276981 $|$ 00 $|$

$|$ 64-IY-98 $|$ 1586183281986 $|$ 00 $|$

$|$ 45-SH-72 $|$ 1586183286989 $|$ 00 $|$

$|$ 42-UW-71 $|$ 1586183311005 $|$ 00 $|$

$|$ 80-DE-01 $|$ 1586183315006 $|$ 00 $|$

$|$ 30-UU-59 $|$ 1586183319009 $|$ 00 $|$

$|$ 78-ST-77 $|$ 1586183324009 $|$ 00 $|$

$|$ 28-MC-82 $|$ 1586183325011 $|$ 02 $|$ KO $|$

$|$ 30-UU-59 $|$ 1586183327012 $|$ 01 $|$ 0 $|$

$|$ 73-FD-20 $|$ 1586183328012 $|$ 01 $|$ 130 $|$

Example of a portion of the \texttt{CAR.TXT} file.

\newpage 
\section{System Architecture} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Modular architecture is very appealing for IoT solutions, as it offers a way to manage the complexity of a problem by breaking it down to smaller and more 
easily manageable modules.
Plus, IoT components are constantly changing and updating, so limiting the effects of such almost organic-like transformations to individual modules allows 
developers to keep in control of the system's growth and functionalities.

Software applications are embracing distributed, decentralized, real time and on-the-cloud as the new norm. 
They are focused on providing real service rather than just being obsessed on lists of features.
This is what drives the increase in awareness for the importance of modularity in software development.
And this is partly what was meant to be explored in this assignment.
So in this chapter we focus on presenting the interacting entities of our vehicle supervising system and the components that constitute their functionality.

\subsection{Entities} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

There are four entities, each with its own set of responsibilities.
These entities simulate the management of the car network, with representative features of what could be accomplished by a fully implemented version.
Following is a description of each and a very simplistic block diagram in Figure \ref{BlockDiagram}.

\vspace{-10pt}
\begin{itemize}[noitemsep]
  \item CollectEntity - its role is to collect data from connected vehicles (represented by \texttt{CAR.TXT}) and produce messages to the other entities with the gathered information (through communication channels established \textit{a priori} and explained in chapter \ref{infrastructure}).
  \item ReportEntity - as the name states, this entity is responsible for reporting all that is transmitted by CollectEntity, writting it to \texttt{REPORT.TXT}.
  \item BatchEntity - Batch's role is to make possible the computation of any relevant metrics and calculations related to the information collected; in our case it merely accomplishes the same as ReportEntity, writting results to \texttt{BATCH.TXT}.
  \item AlarmEntity - its role is to trigger alarms and present them to the system user when some relevant event occurs; in our case alarms are triggered when a car surpasses the predefined speed limit of 120 Km/h; all alarms are written to \texttt{ALARM.TXT}.
\end{itemize}
\vspace{-10pt}

\begin{figure}[H]
  \centering
  \begin{minipage}{\textwidth}
    \centering
    \includegraphics[width=.5\linewidth]{img/BlockDiagram.png}
  \end{minipage}%
  \caption{Basic block diagram for the system, taken from \cite{assign}.}
  \label{BlockDiagram}
\end{figure} 

\subsection{Components} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% responsibilities of each
% other diagrams
...

\subsection{User Interface} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

...

\newpage
\section{Kafka Infrastructure} \label{infrastructure} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As a distributed streaming platform, Apache Kafka has three main capabilities: publish and subscribe to record streams, similarly to a message queue or 
messaging system; store those record streams in a fault-tolerant way; process streams of records as they occur. 
Its general use is for building real-time streaming data pipelines to establish communication between applications, and building real-time streaming applications 
to transform and react to streams of data.

For our specific case, the messaging system scenario seemed the most appropriate.
As stated in their online documentation \cite{kafka}, normally these type of systems follow two possible models: message queueing or publish-subscribe. 
The queue model is characterized by a pool of consumers that read from the messaging server and each record goes to one of the consumers; 
this has several positive aspects such as allowing the division of the records in a balanced fashion by the registered consumers and enabling the processing rate 
and power to scale; on the other hand, being a queue, when a record is processed it may not be reprocessed.
Comparatively, the publish-subscribe model is characterized by broadcasting each record to all registered consumers; this broadcasting feature can be seen as a 
positive aspect, but is counterweighted by the fact that there is no way to scale the process, since every message is sent to every consumer.

With this in mind, we established Kafka's infrastructure as the message system and the backbone for the entire system, making use of both models metioned above.
The usage of this platform was not only a constraint in the proposed assignment, but was also justified by our own personal analysis that showed that Kafka is a 
solution complete enough for our purposes and guarantees a number of quality metrics that were found important.
It was these metrics we explored during development in order to understand their influence on the quality attributes of a system with a standard IoT architecture. 

\subsection{Initialization and Destruction Scripts} %%%%%%%%

Obviously, to use this platform we first needed to instantiate the services and infrastructure composing Apache Kafka. 
To do so, we had two approaches: use the instantiation scripts provided with the source code available online \cite{kafka} or use docker as a middleware 
framework that would enable us to abstract the the instantiation process and use Kafka in a container. 
We chose the former option, which requested more work from our side but enabled us to instantiate the platform with more precision and control.

Manually running each necessary command was obviously out of question.
The solution was to develop two scripts to automate both the creation and deletion of the infrastructure necessary for this project. 
These scripts are available together with the source code, in the package folder \texttt{scripts}.

The initialization script is the first action to be executed when the project is ran.
Also, as you might guess, the deletion script is the last thing to be executed before the system is terminated.
In relation to \textit{initKafka.sh}, the initialization script, it is responsible for: starting Zookeeper, the entity in charge of managing the Kafka Brokers;
initializing the Kafka Brokers themselves, entities with the logic of the platform, for service providing (3 brokers are deployed); creating the necessary Kafka Topics.
The final order of actions performed is:
\vspace{-10pt}
\begin{enumerate} [noitemsep]
  \item Instantiate Zookeeper
  \item Instantiate Kafka Brokers
  \item Store process IDs of the Kafka Brokers in a auxiliary file
  \item Create necessary topics for this project
\end{enumerate}
\vspace{-10pt}
In relations to \textit{deleteKafka.sh}, the deletion script, its responsibility is to kill the processes previously stored in the auxiliary files and delete 
the logs generated by the same processes.
The final order of actions performed is:
\vspace{-10pt}
\begin{enumerate} [noitemsep]
  \item Fetch process IDs from the auxiliary file
  \item Kill the fetched processes
  \item Delete the generated logs
\end{enumerate}
\vspace{-10pt}

\subsection{Topics and Constraints}\label{topics} %%%%%%%%%%%%%%%%%%%%%%%%
To establish constraints to the infrastructure consequently to the project, we had three methods, either in the definition of properties for the consumers, in the definition of the producers or in the definition of properties for the topics themselves.

For this project it was established that there should only exist three topics, the \textit{BatchTopic}, \textit{ReportTopic} and the \textit{AlarmTopic}, each one with the objective of establishing communication between the \textit{CollectEntity} and the \textit{BatchEntity}, \textit{ReportEntity} and \textit{AlarmEntity}, respectively.

.......

\newpage
\section{Additional Remarks} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Documentation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our attitude towards the developed code was to ensure it could be applied to other similar scenarios and reused in systems intended to be deployed in real scenarios.
With this in mind, we took great care with regards to code readability.
By maintaining a code style equal throughout the project and defining intuitive and self-explaining variable and method names, we made the code easy to understand
by someone already contextualized with Kafka.

Nevertheless, we wanted to make sure this was also true to someone looking at our project for the first time, so we resorted to the well-known Javadoc tool to 
manage all code documentation.
Comments were also added in key points throughout the code, including the scripts.

\subsection{Assignment Contributions} %%%%%%%%%%%%%%%%%%%%%%

As the entire development phase took place in a time where on-site cooperation was not possible, we resorted to online communication platforms to debate decisions
and discuss difficulties.
Team scheduling allowed us to work on the project simultaneously, so no member suffered from unbalanced workloads.

The dimension of the project did not appeal to the usage of repository pull requests and other synchronization tools.
However, each small solution was verified and agreed by both team members.

Having said this, it is difficult to isolate what each member actually implemented, as the influence of both is present in all components.
Nevertheless, one might say that each had stronger responsibilities on a set of project aspects:
Filipe took care of the execution of the individual Java processes and of the Shell scripts, while João developed the Kafka-related classes such as Consumer,
Producer and EntityAction; Filipe developed the Python script for generation of \texttt{CAR.TXT}, while João developed the Shell scripts for Kafka initialization 
and deletion; each implemented two entities and each wrote a portion of this report; Filipe made sure everything was coherent throughout the report and the code 
documentation, while João solved the most critical issues regarding the configuration of the Kafka topics, in order to ensure their proper functioning.

\newpage
\section*{Conclusions} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

........................

\begin{thebibliography}{9} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \bibliographystyle{Science}

  \bibitem{assign}
    Óscar Pereira,
    \textit{SA: Practical Assignment no.2},
    University of Aveiro,
    2019/20.
  
  \bibitem{gartner}
    Smarter With Gartner,
    \textit{Staying on Track with Connected Car Security},
    \url{https://www.gartner.com/smarterwithgartner/staying-on-track-with-connected-car-security/},
    accessed in April 2020.

  \bibitem{kafka}
    Apache Kafka,
    \textit{Apache Kafka: A Distributed Streaming Platform},
    \url{https://kafka.apache.org/},
    acessed in April 2020.


  % \bibitem{uml}
  %   Object Management Group,
  %   \textit{What is UML},
  %   \url{https://www.uml.org/what-is-uml.htm},
  %   accessed in March 2020.
    
  % \bibitem{javadoc}
  %   Oracle,
  %   \textit{Javadoc Technology},
  %   \url{https://docs.oracle.com/javase/8/docs/technotes/guides/javadoc/index.html},
  %   accessed in February 2020.

\end{thebibliography}

\clearpage

\end{document}




















